{"title": "NGINX vs. Apache", "content": "<p>The Apache HTTP server and NGINX are the two\u00a0<a href=\"http://w3techs.com/technologies/cross/web_server/ranking\" target=\"_blank\" rel=\"noopener\">most popular open source web servers</a>\u00a0powering the Internet today. When Igor\u00a0Sysoev began working on\u00a0<a href=\"http://nginx.org/en\" target=\"_blank\" rel=\"noopener\">NGINX</a>\u00a0over 10\u00a0years ago, no one expected that the project he created for the purpose of accelerating a large Apache\u2011based service would grow to have the influence it has now.</p>\n<p><a href=\"http://httpd.apache.org/\" target=\"_blank\" rel=\"noopener\">Apache HTTP server</a>\u00a0is a solid platform for almost any web technology developed over the last 20\u00a0years, but time is showing that the architectural decisions made when the code was first laid down are becoming limiting factors in its suitability for modern web demands.</p>\n<p>In this article, I\u2019ll share my perspective on these changes and limitations, and explain how a modern web developer can respond. I write this as a very early user of Apache (and of NCSA\u2019s\u00a0<code>httpd</code>\u00a0before that), as someone who wrote CGI scripts in\u00a0<code>bash</code>\u00a0and Perl before PHP was anywhere near mainstream, and as a one\u2011time software engineer at Zeus, one of the very first event\u2011driven web servers to challenge the Apache model of doing things. My belief is absolutely not that Apache is unfit for purpose, but that in the face of modern web applications, it is now dated and needs support in order to function effectively.</p>\n<h2>The Key to Apache\u2019s Early Success</h2>\n<p>Apache was the backbone of the first generation of the World Wide Web, becoming the industry standard for web serving almost as soon as it\u00a0<a href=\"http://httpd.apache.org/ABOUT_APACHE.html\" target=\"_blank\" rel=\"noopener\">debuted in 1995</a>. It was created at a time when the World Wide Web was still a novelty. Traffic levels were low, web pages were simple, bandwidth was constrained and expensive, and CPU was relatively cheap. There was a huge thirst in the early community to innovate with new technologies, and Apache was the platform of choice.</p>\n<h3>Architectural Simplicity</h3>\n<p>The simplicity of Apache\u2019s architectural model was key to its early success. At that time, many network services were triggered from a master service called\u00a0<code>inetd</code>; when a new network (TCP) connection was received,\u00a0<code>inetd</code>\u00a0would\u00a0<code>fork</code>(\u2009) and\u00a0<code>exec</code>(\u2009)\u00a0a Unix process of the correct type to handle the connection. The process read the request on the connection, calculated the response and wrote it back down the connection, and then exited.</p>\n<p>Apache took this model and ran with it. The biggest downside was the cost of forking a new\u00a0<code>httpd</code>worker process for each new connection, and Apache developers quickly adopted a\u00a0<em><a href=\"http://httpd.apache.org/docs/2.4/mod/prefork.html\" target=\"_blank\" rel=\"noopener\">prefork</a></em>\u00a0model in which a pool of worker processes was created in advance, each ready and willing to accept one new HTTP connection.</p>\n<p>When a prefork Apache web server received an HTTP connection, one of the\u00a0<code>httpd</code>\u00a0worker processes grabbed and handled it. Each process handled one connection at a time, and if all of the processes were busy, Apache created more worker processes to be ready for a further spike in traffic.</p>\n<h3>Easy to Develop, Easy to Innovate</h3>\n<p>The isolation and protection afforded by the one\u2011connection\u2011per\u2011process model made it very easy to insert additional code (in the form of modules) at any point in Apache\u2019s web\u2011serving logic. Developers could add code secure in the knowledge that if it blocked, ran slowly, leaked resources, or even crashed, only the worker process running the code would be affected. Processing of all other connections would continue undisturbed.</p>\n<p>Apache quickly became the dominant web server on the early World Wide Web. Its adoption at websites grew steadily, peaking at over 70%\u00a0market share at the end of 2005.</p>\n<figure id=\"attachment_15562\" class=\"wp-caption aligncenter\"><img class=\"alignnone size-full wp-image-319\" src=\"https://emolike.net/wp-content/uploads/2018/04/apache-market-share-1995-2005.png\" width=\"937\" height=\"589\" alt=\"Netcraft November 2005 Web Server Survey\" srcset=\"https://emolike.net/wp-content/uploads/2018/04/apache-market-share-1995-2005.png 937w, https://emolike.net/wp-content/uploads/2018/04/apache-market-share-1995-2005-300x189.png 300w, https://emolike.net/wp-content/uploads/2018/04/apache-market-share-1995-2005-768x483.png 768w, https://emolike.net/wp-content/uploads/2018/04/apache-market-share-1995-2005-200x126.png 200w\" sizes=\"(max-width: 937px) 100vw, 937px\" /><figcaption class=\"wp-caption-text\">Source: Netcraft\u00a0<a href=\"http://news.netcraft.com/archives/2005/11/07/november_2005_web_server_survey.html\" target=\"_blank\" rel=\"noopener\">November 2005 Web Server Survey</a></figcaption></figure>\n<h2>Challenged by the Growth of the World Wide Web</h2>\n<p>Over the past 20\u00a0years, there has been explosive growth in the volume of traffic and the number of users on the World Wide Web.</p>\n<p><img class=\"alignnone size-full wp-image-320\" src=\"https://emolike.net/wp-content/uploads/2018/04/webgrowth-traffic-users-e1444416038844.png\" width=\"1280\" height=\"362\" alt=\"webgrowth-traffic-users\" srcset=\"https://emolike.net/wp-content/uploads/2018/04/webgrowth-traffic-users-e1444416038844.png 1280w, https://emolike.net/wp-content/uploads/2018/04/webgrowth-traffic-users-e1444416038844-300x85.png 300w, https://emolike.net/wp-content/uploads/2018/04/webgrowth-traffic-users-e1444416038844-768x217.png 768w, https://emolike.net/wp-content/uploads/2018/04/webgrowth-traffic-users-e1444416038844-1024x290.png 1024w, https://emolike.net/wp-content/uploads/2018/04/webgrowth-traffic-users-e1444416038844-200x57.png 200w\" sizes=\"(max-width: 1280px) 100vw, 1280px\" /></p>\n<p>At the same time, the weight of web pages (the size and number of components the web browser has to fetch to render a page) has grown steadily, and users have become less and less patient about waiting for web pages to load.</p>\n<p><img class=\"alignnone size-full wp-image-321\" src=\"https://emolike.net/wp-content/uploads/2018/04/webgrowth-weight-wait1.png\" width=\"1280\" height=\"382\" alt=\"webgrowth-weight-wait\" srcset=\"https://emolike.net/wp-content/uploads/2018/04/webgrowth-weight-wait1.png 1280w, https://emolike.net/wp-content/uploads/2018/04/webgrowth-weight-wait1-300x90.png 300w, https://emolike.net/wp-content/uploads/2018/04/webgrowth-weight-wait1-768x229.png 768w, https://emolike.net/wp-content/uploads/2018/04/webgrowth-weight-wait1-1024x306.png 1024w, https://emolike.net/wp-content/uploads/2018/04/webgrowth-weight-wait1-200x60.png 200w\" sizes=\"(max-width: 1280px) 100vw, 1280px\" /></p>\n<p>(For more details about these changes, check out the list of resources for\u00a0<a href=\"https://www.nginx.com/blog/nginx-vs-apache-our-view/#resources-stats\">Internet statistics</a>\u00a0at the end of this post.)</p>\n<p>All of these changes presented a real challenge to Apache\u2019s process\u2011per\u2011connection model, which did not scale well in the face of high traffic volume and heavy pages (more embedded resources requiring more HTTP requests).</p>\n<h3>Web Clients Greedily Use Resources</h3>\n<p>To decrease page\u2011rendering time, web browsers routinely open\u00a0<a href=\"http://sgdev-blog.blogspot.sg/2014/01/maximum-concurrent-connection-to-same.html\" target=\"_blank\" rel=\"noopener\">six or more TCP connections</a>\u00a0to a web server for each user session so that resources can download in parallel. Browsers hold these connections open (a practice called\u00a0<em><a href=\"https://www.nginx.com/blog/http-keepalives-and-web-performance/\">HTTP keepalive</a></em>) for a period of time to reduce delay for future requests the user might make during the session. Each open connection exclusively reserves an\u00a0<code>httpd</code>process, meaning that at busy times, Apache needs to create a large number of processes.</p>\n<p><img class=\"alignnone size-full wp-image-322\" src=\"https://emolike.net/wp-content/uploads/2018/04/multiprocess.png\" width=\"1050\" height=\"398\" alt=\"multiprocess\" srcset=\"https://emolike.net/wp-content/uploads/2018/04/multiprocess.png 1050w, https://emolike.net/wp-content/uploads/2018/04/multiprocess-300x114.png 300w, https://emolike.net/wp-content/uploads/2018/04/multiprocess-768x291.png 768w, https://emolike.net/wp-content/uploads/2018/04/multiprocess-1024x388.png 1024w, https://emolike.net/wp-content/uploads/2018/04/multiprocess-200x76.png 200w\" sizes=\"(max-width: 1050px) 100vw, 1050px\" /></p>\n<p>Running lots of processes consumes lots of memory.\u00a0<a href=\"http://serverfault.com/questions/254436/apache-memory-usage-optimization\" target=\"_blank\" rel=\"noopener\">Excessive consumption</a>\u00a0results in thrashing and large numbers of context switches, which can slow the web server to a crawl.</p>\n<h3>Admins Fought Against Clients to Recover Resources</h3>\n<p>To mitigate the performance problems of the prefork Apache server, admins were encouraged to adopt two measures. They limited the maximum number of\u00a0<code>httpd</code>\u00a0processes (typically to 256) to avoid exhausting server resources; as a result, when the number of concurrent TCP connections exceeds the number of processes, new connections are stalled indefinitely. Admins also disabled keepalive connections or reduced their duration, in order to free up\u00a0<code>httpd</code>\u00a0processes more quickly.</p>\n<p>Both of these measures have a detrimental effect on the user experience, causing web pages to load more slowly and less reliably.</p>\n<h3>The Apache Team Implemented Alternative MPMs</h3>\n<p>To improve portability and scalability on some platforms, Apache\u2019s core developers created two additional processing models (called\u00a0<em>multi\u2011processing modules</em>, or\u00a0<em>MPMs</em>).</p>\n<p>The\u00a0<em><a href=\"http://httpd.apache.org/docs/2.4/mod/worker.html\" target=\"_blank\" rel=\"noopener\">worker</a></em>\u00a0MPM replaced separate\u00a0<code>httpd</code>\u00a0processes with a small number of child processes that ran multiple worker threads and assigned one thread per connection. This was helpful on many commercial versions of Unix (such as IBM\u2019s\u00a0AIX) where threads are much lighter weight than processes, but is less effective on Linux where threads and processes are just different incarnations of the\u00a0<a href=\"http://stackoverflow.com/questions/807506/threads-vs-processes-in-linux\" target=\"_blank\" rel=\"noopener\">same operating system entity</a>.</p>\n<p>Apache later added the\u00a0<em><a href=\"http://httpd.apache.org/docs/2.4/mod/event.html\" target=\"_blank\" rel=\"noopener\">event</a></em>\u00a0MPM (not to be confused with NGINX\u2019s event\u2011driven architecture), which extends the worker MPM by adding a separate listening thread that manages idle keepalive connections once the HTTP request has completed.</p>\n<h3>Apache\u2019s Heavyweight, Monolithic Model Has Its Limits</h3>\n<p>These measures go some way to improving performance, but the monolithic one\u2011server\u2011does\u2011all model that was key to the early success of Apache has continued to struggle as traffic levels increase and web pages become richer and richer. Performance in lab benchmarks is often not replicated in live production deployments at busy websites, and tuning Apache to cope with real\u2011world traffic is a complex art. Somewhat unfairly, Apache has gained a reputation as a bloated, overly complex, and performance\u2011limited web server that can be exploited by slow denial\u2011of\u2011service (DoS) attacks.</p>\n<h2>Introducing NGINX\u00a0\u2013 Designed for High Concurrency</h2>\n<p>NGINX was written specifically to address the performance limitations of Apache web servers. It was created in 2002 by Igor\u00a0Sysoev, a system administrator for a popular Russian portal site (Rambler.ru), as a scaling solution to help the site manage greater and greater volumes of traffic. It was open sourced in October\u00a02004, on the 47th\u00a0anniversary of the\u00a0<a href=\"http://mailman.nginx.org/pipermail/nginx/2008-May/004816.html\" target=\"_blank\" rel=\"noopener\">launch of Sputnik</a>.</p>\n<p>NGINX can be deployed as a standalone web server, and as a frontend proxy for Apache and other web servers. This drop\u2011in solution acts as a network offload device in front of Apache servers, translating slow Internet\u2011side connections into fast and reliable server\u2011side connections, and completely\u00a0<a href=\"https://www.nginx.com/blog/http-keepalives-and-web-performance/\">offloading keepalive connections</a>\u00a0from Apache servers. The net effect is to restore the performance of Apache to near the levels that administrators see in a local benchmark.</p>\n<p>NGINX also acts as a\u00a0<a href=\"https://www.nginx.com/blog/facing-hordes-black-friday-cyber-monday/\">shock absorber</a>, protecting vulnerable Apache servers from spikes in traffic and from slow\u2011connection attacks such as\u00a0<a href=\"https://en.wikipedia.org/wiki/Slowloris_(software)\" target=\"_blank\" rel=\"noopener\">Slowloris</a>\u00a0and\u00a0<a href=\"https://github.com/shekyan/slowhttptest\" target=\"_blank\" rel=\"noopener\">slowhttprequest</a>.</p>\n<h3>The Secret\u2019s in the Architecture</h3>\n<p>The performance and scalability of NGINX arise from its\u00a0<a href=\"https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/\">event\u2011driven architecture</a>. It differs significantly from Apache\u2019s\u00a0process\u2011or\u2011thread\u2011per\u2011connection\u00a0approach\u00a0\u2013 in NGINX, each worker process can handle thousands of HTTP connections simultaneously. This results in a highly regarded implementation that is lightweight, scalable, and high performance.</p>\n<p><img class=\"alignnone size-full wp-image-323\" src=\"https://emolike.net/wp-content/uploads/2018/04/associated-words-nginx-survey-2015.png\" width=\"845\" height=\"609\" alt=\"associated-words-nginx-survey-2015\" srcset=\"https://emolike.net/wp-content/uploads/2018/04/associated-words-nginx-survey-2015.png 845w, https://emolike.net/wp-content/uploads/2018/04/associated-words-nginx-survey-2015-300x216.png 300w, https://emolike.net/wp-content/uploads/2018/04/associated-words-nginx-survey-2015-768x554.png 768w, https://emolike.net/wp-content/uploads/2018/04/associated-words-nginx-survey-2015-200x144.png 200w\" sizes=\"(max-width: 845px) 100vw, 845px\" /></p>\n<p>A downside of NGINX\u2019s sophisticated architecture is that developing modules for it isn\u2019t as simple and easy as with Apache. NGINX module developers need to be very careful to create efficient and accurate code, without any resource leakage, and to interact appropriately with the complex event\u2011driven kernel to avoid blocking operations. As a result, the success of the NGINX project has rested heavily on the core development team employed by NGINX,\u00a0Inc., the company founded by Igor\u00a0Sysoev in 2011 to ensure the future of the open source NGINX software.</p>\n<p>The\u00a0<a href=\"https://youtu.be/KinJfCQ-WzY\" target=\"_blank\" rel=\"noopener\">announcement at nginx.conf\u00a02015</a>\u00a0of future support for dynamic modules marks the next stage of a third\u2011party developer ecosystem, with fewer barriers to entry than the earlier compile\u2011in architecture.</p>\n<p><em>Editor\u00a0\u2013 NGINX\u00a0Plus Release\u00a011\u00a0(R11) and open source NGINX\u00a01.11.5 introduce\u00a0<a href=\"https://www.nginx.com/blog/nginx-plus-r11-released/#r11-dynamic-modules\">binary compatibility for dynamic modules</a>, including support for\u00a0<a href=\"https://www.nginx.com/blog/compiling-dynamic-modules-nginx-plus/\">compiling custom and third\u2011party modules</a>.</em></p>\n<h2>NGINX and Apache\u00a0\u2013 A Good Starting Point</h2>\n<p>For many application types, NGINX and Apache complement each other well, so it\u2019s often more apt to talk about \u201cNGINX and Apache\u201d instead of \u201cNGINX vs. Apache\u201d. A very common starting pattern is to deploy the open source NGINX software as a proxy (or\u00a0<a href=\"http://nginx.com/products\">NGINX\u00a0Plus</a>\u00a0as the application delivery platform) in front of an Apache\u2011based web application. NGINX performs the HTTP\u2011related heavy lifting\u00a0\u2013 serving static files, caching content, and offloading slow HTTP connections\u00a0\u2013 so that the Apache server can run the application code in a safe and secure environment.</p>\n<p>NGINX provides all of the core features of a web server, without sacrificing the lightweight and high\u2011performance qualities that have made it successful, and can also serve as a proxy that forwards HTTP requests to upstream web servers (such as an Apache backend) and FastCGI, memcached, SCGI, and uWSGI servers. NGINX does not seek to implement the huge range of functionality necessary to run an application, instead relying on specialized third\u2011party servers such as PHP\u2011FPM, Node.js, and even Apache.</p>\n<p><center><br />\n\u201c<em>Apache is like Microsoft Word. It has a million options but you only need six. NGINX does those six things, and it does five of them 50\u00a0times faster than Apache.</em>\u201d</center>\u2014\u00a0<a href=\"http://maisonbisson.com/post/12249/chris-lea-on-nginx-and-wordpress/\" target=\"_blank\" rel=\"noopener\">Chris Lea</a></p>\n<p>For this reason, the market share of NGINX has grown steadily over recent years, as reported in surveys from Netcraft and W3Techs.</p>\n<figure id=\"attachment_15622\" class=\"wp-caption aligncenter\"><img class=\"alignnone size-full wp-image-324\" src=\"https://emolike.net/wp-content/uploads/2018/04/netcraft-top-1m-sept-2015.png\" width=\"1062\" height=\"599\" alt=\"Netcraft September 2015 Web Server Survey\" srcset=\"https://emolike.net/wp-content/uploads/2018/04/netcraft-top-1m-sept-2015.png 1062w, https://emolike.net/wp-content/uploads/2018/04/netcraft-top-1m-sept-2015-300x169.png 300w, https://emolike.net/wp-content/uploads/2018/04/netcraft-top-1m-sept-2015-768x433.png 768w, https://emolike.net/wp-content/uploads/2018/04/netcraft-top-1m-sept-2015-1024x578.png 1024w, https://emolike.net/wp-content/uploads/2018/04/netcraft-top-1m-sept-2015-200x113.png 200w\" sizes=\"(max-width: 1062px) 100vw, 1062px\" /><figcaption class=\"wp-caption-text\">Source: Netcraft\u00a0<a href=\"http://news.netcraft.com/archives/2015/09/16/september-2015-web-server-survey.html\" target=\"_blank\" rel=\"noopener\">September 2015 Web Server Survey</a></figcaption></figure>\n<p><img class=\"alignnone size-full wp-image-325\" src=\"https://emolike.net/wp-content/uploads/2018/04/top-sites-w3techs.png\" width=\"962\" height=\"434\" alt=\"top-sites-w3techs\" srcset=\"https://emolike.net/wp-content/uploads/2018/04/top-sites-w3techs.png 962w, https://emolike.net/wp-content/uploads/2018/04/top-sites-w3techs-300x135.png 300w, https://emolike.net/wp-content/uploads/2018/04/top-sites-w3techs-768x346.png 768w, https://emolike.net/wp-content/uploads/2018/04/top-sites-w3techs-200x90.png 200w\" sizes=\"(max-width: 962px) 100vw, 962px\" /></p>\n<p>(Note that these surveys just detect the software that handles incoming Internet traffic and stamps outgoing responses with an identifying\u00a0<code>Server</code>\u00a0header. They don\u2019t offer much insight into what software and platforms lie within an application.)</p>\n<p>And so emerged the architectural pattern of running NGINX at the frontend to act as the\u00a0<a href=\"https://www.nginx.com/blog/building-great-app-just-beginning-deliver-scale/\">accelerator and shock absorber</a>, and whatever technology is most appropriate for running applications at the backend.</p>\n<h2>Modern Web Applications are Very Different From the LAMP Stacks of the Past</h2>\n<p>You might have heard the buzz around containers,\u00a0<a href=\"https://www.nginx.com/blog/introduction-to-microservices/\">microservices</a>, and lightweight application frameworks such as Node.js and Python/uWSGI.</p>\n<p>We are seeing significant changes in the ways that modern web applications are built:</p>\n<p><img class=\"alignnone size-full wp-image-326\" src=\"https://emolike.net/wp-content/uploads/2018/04/monolithic-to-dynamic.png\" width=\"1040\" height=\"327\" alt=\"monolithic-to-dynamic\" srcset=\"https://emolike.net/wp-content/uploads/2018/04/monolithic-to-dynamic.png 1040w, https://emolike.net/wp-content/uploads/2018/04/monolithic-to-dynamic-300x94.png 300w, https://emolike.net/wp-content/uploads/2018/04/monolithic-to-dynamic-768x241.png 768w, https://emolike.net/wp-content/uploads/2018/04/monolithic-to-dynamic-1024x322.png 1024w, https://emolike.net/wp-content/uploads/2018/04/monolithic-to-dynamic-200x63.png 200w\" sizes=\"(max-width: 1040px) 100vw, 1040px\" /></p>\n<p>Underlying these changes is a desire to achieve faster time\u2011to\u2011market for new web applications and features, by moving away from heavy, monolithic architectures to more loosely coupled, distributed architectures. Continuous delivery is the fundamental driving force behind this shift.</p>\n<h3>NGINX Delivers Microservices Applications</h3>\n<p>Containerized and microservices applications require a stable and reliable frontend that conceals the complexity and ever\u2011changing nature of the application behind it.</p>\n<p>To forward HTTP requests to upstream application components, the frontend needs to provide termination of HTTP, HTTPS, and HTTP/2 connections, along with \u201cshock\u2011absorber\u201d protection and routing. It also needs to offer basic logging and first\u2011line access control, implement global security rules, and offload HTTP heavy lifting (caching, compression) to optimize the performance of the upstream application.</p>\n<p>This is where NGINX and NGINX\u00a0Plus come into their element, providing these\u00a0<a href=\"https://www.nginx.com/blog/12-reasons-why-nginx-is-the-standard-for-containerized-applications-and-deploying-microservices/\">twelve features</a>\u00a0(among others) that make them ideal for microservices and containers:</p>\n<div>\n<div id=\"column1\">\n<ul>\n<li>Single, reliable entry point</li>\n<li>Serve static content</li>\n<li>Consolidated logging</li>\n<li>SSL/TLS and HTTP/2 termination</li>\n</ul>\n</div>\n<div id=\"column2\">\n<ul>\n<li>Support multiple backend apps</li>\n<li>Easy A/B testing</li>\n<li>Scalability and fault tolerance</li>\n<li>Caching (for offload and acceleration)</li>\n</ul>\n</div>\n<div id=\"column3\">\n<ul>\n<li>GZIP compression</li>\n<li>Zero downtime</li>\n<li>Simpler security requirements</li>\n<li>Mitigate security and DDoS attacks</li>\n</ul>\n</div>\n</div>\n<h3>Use NGINX to Give Consistency Within Each Containerized Service</h3>\n<p>Modern, distributed web applications can use a mix of diverse application components, and it\u2019s not uncommon for them to combine a number of\u00a0<a href=\"http://martinfowler.com/articles/microservice-trade-offs.html#diversity\" target=\"_blank\" rel=\"noopener\">different technologies and platforms</a>. The common requirement is that each component be lightweight and scalable, suitable for deploying in containers on a resource\u2011constrained multitenant server.</p>\n<p>Many containers don\u2019t need an embedded web server. They deliver their service using the framework\u2019s own simple HTTP frontend, or using protocols such as FastCGI or uWSGI. In some cases, however, a robust and lightweight web server is required\u00a0\u2013 for example, for efficiency, logging, security, monitoring, or additional functionality. The lightweight nature of NGINX makes it a much better choice to insert in a container than the Apache monolith.</p>\n<figure id=\"attachment_15781\" class=\"wp-caption aligncenter\"><img class=\"alignnone size-full wp-image-327\" src=\"https://emolike.net/wp-content/uploads/2018/04/nginx-microservices.png\" width=\"812\" height=\"720\" alt=\"NGINX serves as gateway and embedded web server in a microservices application architecture\" srcset=\"https://emolike.net/wp-content/uploads/2018/04/nginx-microservices.png 812w, https://emolike.net/wp-content/uploads/2018/04/nginx-microservices-300x266.png 300w, https://emolike.net/wp-content/uploads/2018/04/nginx-microservices-768x681.png 768w, https://emolike.net/wp-content/uploads/2018/04/nginx-microservices-200x177.png 200w\" sizes=\"(max-width: 812px) 100vw, 812px\" /><figcaption class=\"wp-caption-text\">NGINX as gateway and embedded web server in a microservices application architecture</figcaption></figure>\n<h2>Conclusion</h2>\n<p>Apache and NGINX both have their place, and NGINX is clearly in the ascendency. Your requirements and experience might lead you to chose one or both, or even a different path.</p>\n<p>A monolithic architectural framework was sound practice when Apache was new and fresh, but app developers are finding that such an approach is no longer up to the task of delivering complex applications at the speed their businesses require. Microservice architecture is emerging as the wave of the future for web apps and sites, and NGINX is perfectly poised to assume its place in that architecture as the ideal application delivery platform for the modern Web.</p>\n<blockquote><p><a href=\"https://www.nginx.com/blog/nginx-vs-apache-our-view/\">https://www.nginx.com/blog/nginx-vs-apache-our-view/</a></p></blockquote>\n", "slug": "nginx-vs-apache", "date": 1523364864, "cats": [0, 10, 14]}